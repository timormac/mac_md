# 账号相关

```mysql
#工作电脑
账号:linkage
密码:Linkage@12345

#内网账号
绑定笔记本MAC地址:MAC：F0-9E-4A-5C-65-C5
wifi名: EBSCN_ZC
账号:lipc
密码:lpc19950419
金吉路IP：10.81.57.22 （不知道干什么用）

#云桌面
ip地址:10.84.190.70
账号:lipc
秘密:Lpc19950419

#生产库查询
数据服务平台
url:  http://10.0.2.56:8080/smartbi/vision/index.jsp?
账号:zhuanghui   
密码:19841011Jz-1
操作:  定制管理->原生sql查询=>数据源=>数据中心=》数据仓库灾备=>确定

#jira
url:jira.ebscn.com
账号:v_lipengcheng
密码:Windows2024@ebscn


#数据资源平台(实时和接口)
url:10.84.195.196:82
用户名:admin@dtstack.com
密码:DrpEco_2020
流程:数据服务=>数据中心公共接口=>管理API>按接口名搜索


#gp测试库
url：10.84.135.45
数据库:gdzq_dc
认证:database native
账号：gpadmin
秘密:Ebscn601788


#接口测试库  mysql
url:10.84.169.102
数据库:dwdata
用户名:dwuser
密码:dwuser@2021

#大管家h5测试库 mysql
10.84.168.22
root
Dev@321

#大管家h5仿真库 mysql
10.84.199.112
dgjh5_rw
dgjh5@2023


#mot oracle
mot库
10.84.153.191
mot_data_uat
mot_data_uat



#cfjl oracle
10.84.169.27
cfjl
crmii
abs


#gdods oracle
10.84.168.91
gdods
stream
Datastack_12345


#es

#原来用户
把/用户/zhangc/桌面下去看

#kafka测试服务器
服务器地址:10.84.163.119
账号:root
密码:ebscn_EBSCN2020

#redis服务器
10.84.153.184
开发redis登录： ./redis-cli --raw -h 10.84.153.184 -a 123456

#datax服务器
10.84.135.167
root
ebsCN2005


```



# 凌志相关

```mysql
#Oa登陆(手册相关)
工号:c10464
网址:https://oa.linkstec.com:8890
账号:c10464
密码:lpc@12345       老密码 Linkage@12345

#企业微信
网址:  mail.linkstec.com
邮箱: lipc@linkstec.com

```



# 数据资源平台

```mysql
#查看数据接口
流程:数据服务=>数据中心公共接口=>管理API>按接口名搜索


```



# 生产数据导入测试

```mysql
#注意
gp和mysql不一样,mysql没有schema概念，所以dw.tb1  到mysql是dw_tb1

#需求
cfjl/opening_cust_info_yyb
cfjl/open_success_cust_info_yyb  于老师  这两个接口帮忙造点数据  营业部403的

#查接口
登陆数据资源平台(实时和接口)  url:10.84.195.196:82
数据服务 =》API管理 =》选左上角大管家=〉
找sql，看看sql具体是什么，如果很多过滤join那么可以删除，有数据就行。在？？哪里测试跑sql呢
并看配置信息  数据源oracle  数据源名称 realtime_ods_ebscn_openaccount_api


#sql如下:
SELECT a.client_name, a.mobile_tel, a.fund_account, a.branch_no
    , decode(a.business_flag_last, '22241', '完善用户资料', b.business_name) AS business_name
    , a.request_status, e.status
FROM "REALTIME"."RT_CRHKH_CRH_WSKH_USERQUERYEXTINFO" a
LEFT JOIN "REALTIME"."RT_CRHKH_CRH_USER_SYSBUSINESS" b ON a.business_flag_last = b.business_flag 
JOIN "REALTIME"."RT_CRHKH_CRH_USER_BASEDICTIONARY" d ON d.dict_entry = '10100'
    AND a.request_status = d.subentry 
    LEFT JOIN "REALTIME"."RT_CRHKH_CRH_WSKH_PHONEREVISIT" e ON a.REQUEST_NO = e.REQUEST_NO 
WHERE to_char(a.LAST_UPDATE_DATETIME, 'yyyymmdd') BETWEEN ${start_date} AND ${end_date}
    AND a.client_name LIKE (${client_name})
    AND a.MOBILE_TEL LIKE (${mobile_tel})
    AND a.BRANCH_NO = ${branchno}
ORDER BY a.LAST_UPDATE_DATETIME DESC;

需导的数据并不是查询数据，而是保证这个sql用到的表，都有数据就可以。这个sql会自动查表


#生产查数据 
根据ods,去生产库的交易ODS查sql，查询导出


#最后导入哪个库呢

是oracle， 数据源是realteime_ods_ebscn_opean，并且代码里用到的是realtime.tb
找到oracle库gdods,去realtime的库里，找表导入。

导入oracle看一下配置，都是先有的，没有新增的。导入出txt格式




```



# 流平台使用

#### 培训视频

```
https://space.bilibili.com/677474984/video?tid=0&pn=2&keyword=&order=pubdate
```



#### 平台注意事项

```mysql

#flinksql/java都行
自己都试试


#配置checkponit
默认配置文件，都是有checkpoint,觉的不要可以修改，具体看配置文件。
也可以根据自己理解加一些参数

启停策略:9点15开启_16点15关闭等

#平台本身问题
本身有bug,有问题,去微信找袋鼠云找


#注意
维度表字段当on处理的时候，不能做处理的，比如split维度表字段，不可以处理，不然报错

#1.12版本
线上的是flink1.10版本,开发环境是1.12版本，需要去修改一下
看1.12版本的语法和1.10版本不同


```



#### 开户断点需求

```mysql
需求:开户断点

requestid :唯一键，一个用户每次开户都生成一下，失败了重开也会有一条。
reductno  :是开户营业厅，如果没选，就没有，需要处理下
request_state : 审核通过，审核打回(人脸识别不请器，录语音不清晰),办理中，办理成功，申请中， 0-9都是状态,a,b,c,d还有这4个状态
       开户三方存管，就是银行卡绑定开户账号，需要银行和账户号，2方都需要操作来绑定,a,b,c,d就是这个状态。
moible_tel: 手机号

fund_account：资金账号，没有就是没开户成功
channel_code：抖音渠道，同花顺渠道，等渠道
business_flag_last:   上一步骤是什么，（开户的步骤不是固定流程的）
last_update_datetime：上一步骤完成的时间
recommender: 推荐人

#要点
一个客户,任何一个断点，一天只发一次。后序可能变化


#过滤条件
request_state = 0  ; 申请中，只要是0就是客户，需要客户做的东西没做完。


#输出
一个写入kafka 给后端发短信
一个写入oracle 记录kafka推了哪些用户


#配置checkponit
默认配置文件，都是有checkpoint,觉的不要可以修改，具体看配置文件。

启停策略:9点15开启_16点15关闭等



#新需求
15分钟中断时间,上传身份中断8分钟就发消息。如果身份证发了，那么其他15分钟的就不能发了。

线上的是flink1.10版本,开发环境是1.12版本，需要去修改一下

#注意
维度表字段当on处理的时候，不能做处理的，比如split维度表字段，不可以处理，不然报错



#flinksql解析
mobile_tel,business_flag_last,channel_code,to_date(last_update_detetime)
1 ：表1按 手机号,流程到哪,渠道码,日期 开窗，按时间来 order，过滤rk=1,那么第一条来的数据永远都是1,保证了同一个状态只有一条数据。
2 ：会话窗口,超过8分钟没来消息就关闭会话， 返回最后一条
3 ：会话窗口返回的数据，通过流再做一次去重（步骤就是取窗口最早时间第一条，这样即使后面来数据了，根据rank，也是最早的是第一个，不会重复输出）



#问题
1.只有上一个步骤,怎么判断当前是身份证认证.
1.怎么只发一次
2.怎么把（其他事15分钟,身份证是8分钟）2个分开（目前想到的是写入mysql中，这样维表关联确定是否已经发过了）



#生产把代码弄到开发
先生产打包 然后安渡  然后扔开发环境
```







#### 私募冷静期回访

```mysql
#040需求
私募冷静期回访？？不知道是不是有bug，目前没数据。逻辑在040代码里



```



#### 需求2

```mysql
元数据变更评估


表里有crh不管大小写的，custom_sql like "crh"


#dbeaver手动刷新
```





# jira使用

```mysql
#提交任务
提交脚本到jr里
```



# debeaver使用

```mysql
#数据库导航
窗口=>数据库导航

```

