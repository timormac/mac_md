# clickhouse角色

### 简介

```mysql
实时任务中，如果不使用clickhouse，，我们计算今日的数据统计，需要手动记录一个当前累加结果再redis或者mysql，并且需要处理故障恢复，怎么保证这个累加值是正确的，好像也无法判断这个累加值是到哪一步的统计结果。

用clickhouse是临时计算，也是秒级查询。相比mysql查询结果靠谱多了，因为可以实现幂等性，并且是临时统计，能保证结果数据是正确的。

他的计算快的原理，我感觉是，你建表时需要指定你聚合的口径，累加哪些数值。比如你按时间聚合，统计当天的总金额，总单数，可能会像kylin一样，预聚合，临时插入的数据尚未聚合的，进行临时聚合,来保证速度
```



# SparkStreaming

### 架构

### 需解决问题

```mysql
#两个实时表流关联,延迟问题
双流join中，在spark是2个流窗口进行join，如何保证延迟问题，数据不丢
思路1: 先延迟，还找不到再输出流

#故障时，如何保证恢复时，数据正确
难点在于手动提交offset时，下游怎么保证事务，并且怎么保证下游数据不会重复计算
思路1:定期手动对数，或者脚本对数
这个涉及了，ads展示层，是怎么实现展示逻辑的，如果只存一个值，会有问题，如果是从clickhouse临时计算，没有问题。并且clickhouse可以实现类似幂等性的功能(待确认)。



#保证数据正确
根本问题还是上面2个，
如何保证数据不丢
以及数据会不会重复消费
故障恢复逻辑，保证正确


```



### 解决方案







# FlinkStreaming

### 架构

### 需解决问题

```mysql
#两个实时表流关联,延迟问题

双流



```



### 解决方案