# 面试总结

```mysql
#业务场景方面
思考多场景：
1	flink的久状态，短期状态，大状态，小状态，超大状态的设计方式,维度表怎么存(如果维度表很大,放入hbase中，要想提交查询速度，近1天的热点商品先查redis，差不到去查hbase，再写入redis)
2 不同场景下checkpoint设计（待补充）
3 不同场景下ttl设计（待补充）

#技术栈方面
flink内存模型,提交流程,这种了解就行。背了不修改源码，用不上

```



# 项目概览

### flink实时项目

```mysql
#项目难点(问题处理)
1. ？？？老用户半年没未消费 （不行，基本都要去hbase查一下）（是不是只能一个并行度）

订单全量放在hbase，查询是查本地布隆过滤器,如果查到那么,去查hbase确认

把历史订单数据导入kafka,flink流消费kafka,先判断是否消费过(布隆过滤器)，
未消费,放入
查到已消费


2. 首次消费用户(???有问题)
永久状态存储,用户首次消费,发一个消息到kafka，后序处理。
keyby的逻辑,keyby，放入一个value<boolean中>，这个方案不行。keyby后，每个id都自己维度，状态太多了
用布隆过滤器结合bigtable。如果布隆过滤器，判断一定不存在，不用去查。判断可能存在，再去查hbase。减少外部hbase查询次数。

按用户id取模并行去，然后本地缓存，布隆过滤器

但是这个提升效率有限,大部分都是非首次消费,基本都要去查hbase。如果数据量很大的话,基本都是重复用户

#配置表用广播变量优点
1问题  多并行度下,数据都能关联到
2问题  减少shuffle
3问题  动态控制
如果想实现每个流，多并行度下都能关联到配置表，不会漏。那么维度表按table名keyby，然后connect也能实现，不会丢数据。
但是从kafka消费的数据，都会经过一次keyby的shuffle。不划算，广播变量就能减少数据移动。

#动态采集mysql维度表数据
广播变量,多并行度就是不能按table进行keyby

#大状态维度表，每次访问问题
每个订单消息,访问hbase延迟高,对hbase压力也大。
小维度表：广播变量将维度存在flink状态内存
大维度表：
1.在本地做缓存通过guava cache,或者redis缓存
2.按维度表id进行并行度分区,对维度表拆分成多个部分
3.异步查询hbase+guava缓存，异步查询hbase，会不阻塞下一个数据执行，也就是说，在并行执行多个hbase查询


某些场景匹配不是太精准,或者只是判断是否存在问题,就用布隆过滤器


#案例
订单,关联商品表,关联用户表,关联商户表。
统计当天订单数,订单金额,用户数,top商品售卖数,购买渠道(app，小程序,公众号推文)。
各小时订单数,订单金额,用户数,top商品售卖数,购买渠道(app，小程序,公众号推文)

#statebackend
（细节需要写项目发现）
哪些状态用rockdb: 
		每个图标点击次数，点击的人数,
		实时热门商品,商品购买人数
		统计当天购买人数(去冲)，多次下单
哪些状态用hashmap:各小时商品售卖数

#ttl
统计各小时商品售卖数,按dt|spu作为key,然后设置ttl为1小时
按天统计的指标设置第二天过期，按dt|sku

#checkpoint故障恢复数据正确
设置checkpoint，应根据ttl时间，确定是用changelog增量变化，还是状态整体同步。

kafka偏移量提交是通过 checkpoint 统一提交的。当偏移量还原时，累加值操作也会还原，没有问题。
如果不是checkpoint统一提交，手动提交，那么累加值无法保证。
累加值还原了，不过重复消费问题没解决,这个需要下游幂等性来做？具体待补充

#flink精准一次性消费kafka
设置checkpont at-least,at-most,exctl


#合理分配资源
全局压测测并行度：kafka积压数据,开flink任务，查看单个并行度的qps,对比峰值qps
source端并行度:默认是kafka分区数，变为一半或1/3,看看反压


#数据流join（问题待解决）
flink是流处理，可以2个流connect得到conn流。因为多并行度需要keyby会对key取hash进行分配并行度。
然后再process里定义2个map进行存储，流数据进入，进行关联



```

### 离线在线混搭

```mysql
#表任务筛选
ods层新增和变化的表大表,这种表在hive中,动态分区插入,join关联历史表效果不好。
主业务表：订单,核销，预约表。

#框架选型
实时任务,要能支持实时高效写入.
筛选的表，有变更数据,要能支持数据变更
flink故障恢复问题，要能支持重复数据解决.

hbase 支持数据变更，幂等性,不过绑定hql表查询任务是走服务器,性能需要优化
hudi 支持数据变更,对于hive更友好，执行hql走mr程序。

#解决数据更新,重复数据问题
重复问题是chekpoint故障恢复时会有，kafka是由ck来提交的
更新直接写入hbase

#hbase表rowkey的合理设计，以及查询性能问题
hbase表不支持hive分区,需求过滤当天订单，2个方案
方案1: rowkey是日期+订单号,利用hbase前缀过滤,不过这个会出现热点问题,历史订单表都在一个region,性能不好
方案2: 设置日期二级索引,如日期+订单号,虽然会集中在

#任务变更
原来的都是过滤分区，现在把日志索引作为那个字段


```



### 数仓质量管理



```mysql
#数仓中的链路表进行条数，度量进行校验
出现条数不一致原因,模型变动覆盖不到。维度表多条,后端只取一条
每日脚本,hive中数据，条数，总金额数，写入hbase，然后人工配置一些校验。条数不为0,条数相等，总额度相同。
还有些通过指标推指标的,不过逻辑复杂。


#通过血缘关系找到重复中间表进行合并，制定临时表建表规范(好复杂)
元数据表，记录表的血缘表,统计口径(group by ,full,filter)
建表时输入到的关联关系表,查询是有已有临时表，如果字段没覆盖到,字段补充




#历史任务监控，停用
这个没实现想法，方案起来了
```



```mysql
设计一个系统来记录Hive数据仓库中所有表的数据来源并允许用户查询这些信息，可以通过以下几个步骤来实现：

### 1. 元数据收集

首先，您需要收集和记录每个Hive表的元数据。这些元数据应该包括：

- 表名
- 数据来源（可以是其他表名、外部数据源如HDFS路径、或者是数据导入的工具如Sqoop）
- 表的创建者和创建时间
- 表的更新频率和最后更新时间 (可以知道是否可用)
- 表的数据量（行数或大小）
- 表的字段信息（包括字段名、字段类型、字段描述等）
- 表的依赖关系（哪些表是通过当前表的数据转换得到的）

### 2. 元数据存储

创建一个中央元数据存储库，可以是一个Hive表，一个关系型数据库，或者是一个专门的数据目录服务，如Apache Atlas。这个存储库用于存放上一步收集的所有元数据。

### 3. 元数据更新机制

建立一个机制，每当有新表创建、旧表更新或删除时，都能够自动更新元数据存储库。这可以通过Hive的Hook机制来实现，或者通过定期运行的作业来扫描Hive元数据并同步更新。

### 4. 查询接口设计

设计一个用户界面或者API，允许用户输入表名，查询系统，并返回相关的元数据信息。这个接口应该能够：

- 接收用户查询请求
- 从元数据存储库中检索信息
- 将结果以用户友好的方式展示出来

### 5. 用户界面设计

为了方便新人使用，您可以设计一个图形界面（GUI）或者命令行界面（CLI），通过简洁直观的方式让用户查询表的元数据。

### 6. 系统集成

将上述系统集成到现有的数据仓库管理工具中，例如通过集成到Hive的Web UI中，或是其他数据管理平台。

### 技术栈建议

- **前端**: React/Vue/Angular等现代前端框架，用于构建用户界面。
- **后端**: Spring Boot/Flask/Django等，用于处理业务逻辑和与元数据存储库的交互。
- **数据库**: MySQL/PostgreSQL/Hive自身，用于存储元数据。
- **数据目录服务**: Apache Atlas，用于集成数据源的元数据管理。
- **数据采集**: Apache NiFi/Sqoop等，用于自动化数据流和元数据收集。

### 7. 安全性和权限管理

确保您的系统中包含适当的安全性和权限管理机制，以保护敏感数据，并确保只有授权用户能够访问相关信息。

### 8. 文档和培训

编写清晰的文档，对新人进行培训，以确保他们能够有效使用这个系统。

通过这样的系统，新人可以轻松地查找到所需的数据表及其来源，加快了数据仓库的使用效率，减少了重复工作的可能性。
```



### spark实时项目

```mysql
#双流join,状态缓存处理
窗口，关联不到的,存redis 存10s,如果想看，监控redis过期消息。

#故障恢复,保证链路精准，精准一次性
之后个别要非常准确的任务，才这么做，开发难度大。

和flink类似,保存kafka偏移量,以及中间状态存在mysql中,最好能把redis的也存起来,
重启时查询mysql是否有数据。
具体就是每1000条,进行一次mysql状态存储。并且要把偏移量，传递给下游,这样下游根据这个偏移量，也做确认，触发了把中间状态存下来。
然后故障时统一恢复所有状态。这里还有个分布式合流问题。好像很复杂

#维度表存储问题
广播变量,变更的数据,gpt说有mapWithState这些

#首次消费问题
状态大存redis不合适，每次访问hbase也不合适,布隆过滤器

```





### 数仓模型设计

```mysql
#ods
业务数据每日导入方式,订单 新增及变化。分区增量，修改
小维度表，全量，保证历史状态
大维度表，拉链表
#dim
小维度表,分区，每日全量，保持历史状态。
关联相关的维度表，冗余部分字段，还有相关主键，方便字段覆盖不到是时，查询
大维度表 用户表新增及变化(如果是拉链表用什么分区呢？)
#dwd
和ods差不多,区别就是和dim关联,放入维度相关其他主键,做数据清洗（日期格式转换，空值处理）。保证相关表能关联一次拿到
脏数据原因，后端没落部分字段(标题,部分字段)。

#dws
按统计维度去聚合一些数据,方便数据重复利用
#dwt
```



# 技术栈

### flink

```mysql
#taskmanager内存模型
1 jvm的特定内存：
 			over-head 执行内存taskmanager.memory.jvm-overhead.fraction 0.1比例
 			jvm metaspace内存256M

2 框架堆内存：Flink 框架，即 TaskManager 本身所占用的内存，去除掉jvm内存分给下面3个
	堆内：taskmanager.memory.framework.heap.size，默认 128MB
	堆外：taskmanager.memory.framework.off-heap.size，默认 128MB
	
3 Task 内存：Task 执行用户代码时所使用的内存
	堆内：taskmanager.memory.task.heap.size，默认 none，由 Flink 内存扣除掉其他部分的内存得到。
	堆外：taskmanager.memory.task.off-heap.size，默认 0，表示不使用堆外内存
	
4	网络内存：网络数据交换所使用的堆外内存大小，如网络数据交换缓冲区堆外：
		taskmanager.memory.network.fraction，默认 0.1
		taskmanager.memory.network.min，默认 64mb taskmanager.memory.network.max，默认 1gb
		Flink 内存*fraction，如果小于配置的 min（或大于配置的 max）大小，则使用 min/max大小
		
5	托管内存：用于 RocksDB State Backend 的本地内存和批的排序、哈希表、缓存中间结果。
  堆外：taskmanager.memory.managed.fraction，默认 0.4
   taskmanager.memory.managed.size，默认 none
  如果 size 没指定，则等于 Flink 内存*fraction






#参数调优

#资源合理分配

#状态编程

#任务监控

#反压机制

#精准一次性消费

#flink-core核型原理


#flink-sql
```



### hive

```mysql
#参数调优
开启 map join,根据集群内存规模yarn的container大小,hdfs的块大小,设置合理的小表大小
开启map端预聚合,合理设置抽样,根据块大小,数据量条数，设置超过多少条开机预聚合
开启skew join,设置数据量超过多少，进行热点join处理


#执行计划
from的表，不需要select需要字段，hive优化器会根据你用到的字段，自动过滤。直接from a就行



#数据倾斜问题
1 热点key group场景,大部分预聚合。不能预聚合的加随机数聚合一次,然后去随机数再聚合一次
2 空值问题，空值打散，if判断如果key是"",则加随机数,若非空则正常，关联维度表会自动过滤掉空值
3 热点key join场景下,给key+｜随机数(1-10),然后维度表去笛卡尔积1-10扩大10倍。这个场景是维度表数量级远小于主表,但是维度表也相对	大，不能mapjoin加载到内存
4 热点key join场景下,热点单独处理：
   	先从大表 执行group by shopid having count(*)>100000,来找出热点商铺。因为groupby 可以执行map端预聚合，所以shuffle			时,数据量小,不会出现group by这里出现热点问题导致速度慢，然后存入临时表。

  	用大表 join 热点商户表,过滤出热点商户数据,因为热点商户表数据很小，这里是mapjoin没有大批量shuffle。
		然后中维度表关联热点表,过滤出热点商户维度，再关联上面过滤的，中维度表过滤后，也是小表是map join 没有shuffle

  	总结为什么会快
		步骤1执行后的数据,步骤2执行后的数据都是临时mr数据，因为都是mapjoin，所以reduce结果都在本节点落盘。
		当在join时，把维度表作为mapjoin，这样热点数据是多服务器计算，不是单服务器，并且没有跨节点的shuffle落盘，只有本地落盘



#hive优化--------
# 拉链表  
数据量大的维度表，每日变化不多

#合理设置map,reduce数
减少map任务数：在map执行前合并小文件，减少map数：CombineHiveInputFormat具有对小文件进行合并的功能（系统默认的格式）
reduce数：用hive自己的算法,默认:每个Reduce处理的数据量默认是256MB


#减少小文件数
1  在map-only任务结束时合并小文件，默认true 。SET hive.merge.mapfiles = true;
2  在map-reduce任务结束时合并小文件，默认false  SET hive.merge.mapredfiles = true;
	 合并文件的大小，默认256M  SET hive.merge.size.per.task = 268435456;
	 当输出文件的平均大小小于该值时，启动一个独立的map-reduce任务进行文件merge，SET hive.merge.smallfiles.avgsize = 		    16777216;



```



### spark

### kafka

### hbase

### hadoop





# hive八股文

### 数据倾斜

```mysql
#出现场景
主要是热点问题,某个key占绝大部分数据,导致groupby或者join倾斜。
热点问题，第一个就是空值/默认值，第二个就是热点

#解决方案1 mapjoin
大表join小表
map join,默认有个20m配置,如果集群内存够大可以修改这个参数。

#方案2 热点key打散
1 空值，默认值情景打散，if判断如果key是"",则加随机数,若非空则正常，关联维度表
2 热点key打散,在groupby场景下,给key+｜随机数(1-10)先聚合一次，然后再按｜切分再聚合一次
3 热点key打散,在join场景下,给key+｜随机数(1-10),然后维度表去笛卡尔积1-10扩大10倍。这个场景是维度表数量级远小于主表,但是维度表也相对大，不能mapjoin加载到内存



#方案3 热点单独处理
大表join中维度表
1 先从大表 执行group by shopid having count(*)>100000,来找出热点商铺。因为groupby 可以执行map端预聚合，所以shuffle时,数据量小,不会出现group by这里出现热点问题导致速度慢，然后存入临时表。

2 用大表 join 热点商户表,过滤出热点商户数据,因为热点商户表数据很小，这里是mapjoin没有大批量shuffle。
然后中维度表关联热点表,过滤出热点商户维度，再关联上面过滤的，中维度表过滤后，也是小表是map join 没有shuffle

3 总结为什么会快
步骤1执行后的数据,步骤2执行后的数据都是临时mr数据，因为都是mapjoin，所以reduce结果都在本节点落盘。
当在join时，把维度表作为mapjoin，这样热点数据是多服务器计算，不是单服务器，并且没有跨节点的shuffle落盘，只有本地落盘

4 再union all非热点数据，和流程2一样，区别就是非热点的商户是个大表，不能mapjoin。这里就是热点的mapjoin+非热点的shuffle


```



# flink八股文

### 任务提交模式

```mysql
#session
session和application都是yarn模式，
session只有一个集群,适合长久运行和频繁提交作业,session模式下,JobManager 和 TaskManager是分开的,提交的多个flink任务共用一个JobManager.
session只会启动一个flink集群,

#application
run-application模式下，JobManager 和 TaskManager 是一起的。JobManager 和 TaskManager 运行在同一进程中，共享相同的资源，这种模式适用于单机或小规模的部署。
但是session模式下,JobManager 和 TaskManager是分开的，所有任务共享一个JobManager

#per-job
per-job和run-application，每个任务都会单独启动集群，不过run-application和yarn对接更好，如历史服务器等。

#对比
session模式能减少创建jobmanager的开销,application最好是某个单独任务需要独立的，怕被影响的，或者独自内存需求很大的
```

### 架构模型

```mysql
#jobmanager

#taskmanager
是一个jvm进程，每个taskmanager，都需要启动个yarn的container
slot时taskmanager的线程，taskmanager的jvm可以有多个线程slot,

#slot
虽然多个slot是一个taskmanager的jvm下，但是slot不共享内存，2个算子还是要序列化和反序列化。
可以理解成每个slot是单独的程序，只是在同一个jvm下运行。

3个map算子到key by 到1个keyed算子，一共4个任务:3+1    3个slot就可以执行
一个slot可以执行多个算子，既可以在map阶段算子，也可以处理reduce阶段的算子。
如果某个算子工作量大，可以不设置slot共享，这样那个算子会单独占用一个slot。

案例1
yarn-session模式下，启动时设置4个taskmanager,每个4个插槽，共16个slot。你占用15个，剩下一个还是可以提交flink任务的。
因此同一个jvm,不同slot可以执行不同的flink任务，所以slot之间不互通

案例2
yarn-session模式下，启动时设置4个taskmanager,每个4个插槽，共16个slot。你占用15个，剩下一个还是可以提交flink任务的。
因此同一个jvm,不同slot可以执行不同的flink任务，所以slot之间不互通
一个jvm可以执行多个不同的java任务。java a.class指令，每次执行会单独创建一个jvm。可以通过工具提交java任务，到之前的jvm。
这个就是以前不理解的jvm重用，现在理解了。


#注意
虽然多个slot是一个taskmanager的jvm下,虽然多个slot共享内存，2个算子还是要序列化和反序列化。
可以理解成每个slot是单独的程序，只是在同一个jvm下运行。
个人理解是flink拆解任务时，不能根据你slot的上下游是否在一个taskmanager中，来优化不用序列化
因为有的是不在一个taskmanager中的，必须序列化，为了统一只能统一都序列化


```

### 反压机制

### 编码概念

#### state

#### ttl

#### checkpoint

#### statebackend

#### watermark









# spark八股文