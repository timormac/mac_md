# 遇到问题

#### sqoop脚本报错

显示没有 --target-dir的command ，

字符串 \ 表示这是一行数据，注意\必须放在末尾，后不能有空格，并且脚本里有个空换行，也不行，

注意因为不是sh里面，执行的sqopp指令 --后有#注释也不行，会把注释传给sqoop参数 --dir把注释作为参数了



# 集群服务器规模(和上面合并一下)

6台服务器   16核    128g内存   40T      一个服务器一台1年是3w     一年6台20多w



服务器编号 1- 6

这个mysql是主库备份

配置原因：

namenode占用大量内存，不做执行yarn任务

mysql和sqoop要导数据, hive从mysql读源数据



1  namenode        hive    mysql    sqoop

2  namenode(ha)

6 resource

3 data

4 data

5 data





### hadoop

1台namenode    

3台datanode

1 Ha namenode + datanode 

1 resourcemanager  +datanode 



### kafka /zookeeper

转一起因为通信

5个

3个容忍1个错误



### sqoop/mysql/maxwell一起

这3台装一起，sqoop和maxwell从mysql读数据

### hive/flink/spark

都安2台，防止挂掉。

注意这3台，必须放一起，hive配置spark引擎，还有flink的catalog连接hive。都要互相制定对方的配置文件和目录等。

如果不放在一起，根本找不到对应的配置文件。









### azkaban

在







# 后期目标

自制化机群需要实现：

1 从kafka和mysql 界面同步数据

2 人员表权限管理

3 调度任务周期设置,依赖关系，血缘关系

4 git 历史版本 

5 线上，测试双环境

6 任务执行日志在线观看



## 组件版本兼容问题

比如zookeeper和kafka等组件，当自己调研的时候需要适配版本，如果版本不同，可能kafka用到了zk的A类，别的版本A类的名字变了，或者方法变了，导致报错。或者版本低了，导致没有用到的类。

解决方法，有的需要修改源码，再打包上传jar包。



hive3.1.2和spark3.0不兼容，要改源码替换类和方法，才能兼容







## sqoop

## 

## kafka

## flume

##### 待解决问题

flume消费kafka上传到hdfs上，每10s一个滚动，会出现小问题件过多问题吗？还是会追加到已有的文件中



# 架构比对

### 行为日志flume和直接kafka对比

gpt3.5

```
这两种公司架构的优缺点如下：

第一种架构（前端埋点数据发送给nginx服务器，然后落盘本地，再用flume监控文件发送到kafka）的优点：

1. 数据可靠性高：数据先落盘在本地，即使出现网络故障或者kafka不可用的情况，数据仍然存在于本地文件中，不会丢失。
2. 低延迟：前端数据直接发送给nginx服务器，不需要等待kafka的响应，可以实现较低的延迟。
3. 灵活性：通过使用flume监控本地文件，可以实现对文件变动的实时监控和处理，可以灵活地进行数据转发、过滤、转换等操作。

第一种架构的缺点：

1. 需要额外的组件：使用flume进行文件监控需要额外的配置和维护，增加了架构的复杂性。
2. 存储成本高：数据首先需要落盘在nginx服务器本地，可能会占用较多的存储空间。

第二种架构（前端埋点数据直接发送到nginx服务器，服务器直接发送到kafka）的优点：

1. 简单高效：数据直接从nginx服务器发送到kafka，减少了中间步骤和组件，简化了架构，提高了数据传输的效率。
2. 存储成本低：数据不需要落盘在本地，减少了存储成本。

第二种架构的缺点：

1. 数据可靠性较低：数据直接发送到kafka，如果kafka不可用或者网络故障，数据可能会丢失。
2. 高延迟：前端数据需要等待nginx服务器将数据发送到kafka并等待kafka的响应，可能会导致较高的延迟。

哪种架构更好取决于具体的业务需求和实际情况。如果数据的可靠性和低延迟是关键考虑因素，第一种架构可能更合适。如果对数据可靠性要求不高，但追求简单高效的架构，第二种架构可能更适合。需要根据具体的业务场景和需求来选择适合的架构。
```



gpt4

```
两种架构各有优缺点，适用于不同的场景和需求。下面是对这两种架构的优缺点分析：

### 通过Nginx落盘然后用Flume监控并发送到Kafka

#### 优点：
1. **数据可靠性**：由于数据首先被写入本地磁盘，这就提供了一个缓冲，确保了即使在网络或Kafka出现问题时，数据也不会丢失。
2. **灵活性**：Flume提供了数据过滤、转换等功能，可以在数据发送到Kafka之前进行一些处理。
3. **容错性**：如果Kafka不可用，数据仍然可以在Nginx服务器上保存，待Kafka恢复后再进行传输。

#### 缺点：
1. **延迟**：数据需要先写入磁盘，再由Flume读取并发送到Kafka，这会增加数据从产生到可用的时间。
2. **维护复杂性**：除了Nginx和Kafka的维护，还需要额外维护Flume和磁盘空间。
3. **性能开销**：磁盘I/O可能会成为瓶颈，尤其是在高吞吐量的场景中。

### Nginx直接发送数据到Kafka

#### 优点：
1. **低延迟**：数据可以直接从Nginx发送到Kafka，减少了写入磁盘的时间，从而减少了总体的数据处理延迟。
2. **架构简单**：减少了Flume的使用，简化了数据流动的链条，降低了维护的复杂性。
3. **性能**：减少了对磁盘I/O的依赖，能够更好地处理高吞吐量的数据。

#### 缺点：
1. **数据可靠性**：如果Kafka出现问题，而Nginx没有足够的缓冲机制，可能会导致数据丢失。
2. **缺少中间处理**：直接发送数据到Kafka，意味着失去了在数据到达Kafka前进行额外处理的机会。

### 哪个更好？

这取决于具体的业务需求和场景：

- 如果数据可靠性是首要考虑的因素，并且需要在数据传输到Kafka之前进行某些处理，那么第一种架构可能更适合。
- 如果需要低延迟和简化架构，并且可以承受偶尔的数据丢失，那么直接将数据从Nginx发送到Kafka的方案可能更合适。

在实际的应用中，可能还需要考虑其他因素，比如网络的可靠性、系统的扩展性、成本和资源的可用性等。通常，选择哪种架构都需要在不同的优缺点之间进行权衡。
```

3和4的说法不一致

对不起造成了混淆。让我来澄清一下：

在直接将数据从Nginx发送到Kafka的架构中，理论上应该是具有**较低延迟**的，因为数据不需要首先被写入磁盘，而是直接通过网络发送到Kafka。这种方法减少了数据在传输过程中的等待时间，因此通常会比先写入磁盘然后再传输的方法更快。

相反，在通过Nginx落盘然后用Flume监控并发送到Kafka的架构中，会有**更高的延迟**，因为数据需要先被写入磁盘，然后Flume再将数据发送到Kafka，这个过程增加了额外的步骤和时间。

因此，就延迟而言，直接从Nginx发送到Kafka的方案通常会有更低的延迟，这是因为它省略了写盘和读盘的过程。如果您看到的另一个答案与此相冲突，那么可能是对该方案的误解。在实际部署中，确实需要考虑到Kafka的响应时间，但这个时间通常比写入磁盘和再由Flume处理的时间要短。





### 完全抛弃flume

flume用途: 采集落盘日志数据发送到kafka，从kafka消费数据到hdfs

减轻架构就是,后端直接数据发kafka，kafka数据用spark streaming处理，还能做数据复杂操作。



### 

