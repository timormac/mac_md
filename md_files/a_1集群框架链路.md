## 遇到问题

#### sqoop脚本报错

显示没有 --target-dir的command ，

字符串 \ 表示这是一行数据，注意\必须放在末尾，后不能有空格，并且脚本里有个空换行，也不行，

注意因为不是sh里面，执行的sqopp指令 --后有#注释也不行，会把注释传给sqoop参数 --dir把注释作为参数了



## 目标

自制化机群需要实现：

1 从kafka和mysql 界面同步数据

2 人员表权限管理

3 调度任务周期设置,依赖关系，血缘关系

4 git 历史版本 

5 线上，测试双环境

6 任务执行日志在线观看



## 组件版本兼容问题

比如zookeeper和kafka等组件，当自己调研的时候需要适配版本，如果版本不同，可能kafka用到了zk的A类，别的版本A类的名字变了，或者方法变了，导致报错。或者版本低了，导致没有用到的类。

解决方法，有的需要修改源码，再打包上传jar包。



## sqoop

## 

## kafka

##### 待解决问题

如何保证精准一次消费,怎么实现



## flume

##### 待解决问题

flume消费kafka上传到hdfs上，每10s一个滚动，会出现小问题件过多问题吗？还是会追加到已有的文件中



# 集群服务器规模(和上面合并一下)

6台服务器   16核    128g内存   40T      一个服务器一台1年是3w     一年6台20多w



服务器编号 1- 6

这个mysql是主库备份

配置原因：

namenode占用大量内存，不做执行yarn任务

mysql和sqoop要导数据, hive从mysql读源数据



1  namenode        hive    mysql    sqoop

2  namenode(ha)

6 resource

3 data

4 data

5 data





### hadoop

1台namenode    

3台datanode

1 Ha namenode + datanode 

1 resourcemanager  +datanode 



### kafka 

5个



### zookeeper

3个容忍1个错误



### sqoop

1个

### hive

2个防止一个挂掉，在另一个上启动脚本

### azkaban

在

### spark

