# 问题待解决

#### kafkasource重复消费

```mysql
kafkasource代码没修改，2次执行,都是从头消费。并且第一次执行好像没有提交偏移量。奇怪
```

#### 其他小问题

```mysql
#状态无法恢复
我把状态用chekpont提交了，为什么执行重启后,value还不是累积值呢？有个if null判断还是会判断成,
代码A1_统计每小时消费

没设置状态后端，使用的默认的状态后端。
设置了fs后端，还是累积值从0开始，不知道为什么，真七块

#idea导入以来后，报错找不到rockdb相关lib，无法再本地存状态
好像是检查点默认不会去存自定义状态，只有状态后端才会去存
rockdb会把检查点存在本地一份。但是检查点不会把状态后端也存一份，默认的memory就不会存到hdfs上的检查点

#实时任务中
dim配置表加载mysql数据时,再次启动/首次启动，会不会出现这时候,维度表有变动数据，但是配置广播流还没加载出来，导致遗漏数据呢


```



# 场景代码篇

## 场景解决方案

```mysql
#同流，相同key,相差超过3分钟,处理
监控订单表变化，订单表下单后，产生一条数据写入flink流中。当订单变为支付状态后，也会产生一条数据进入flink流。目前的要求是下单后3分钟内，订单未支付，则标记订单失效。

方案1：keyby后，process方法，process维护一个ValueState<Boolean>,定时器3分钟触发操作写。
			只有下单消息才创建定时器，支付不创建定时器逻辑。
			设置ttl 3分钟后state小时
			
方案2:keyby后创建会话窗口，超时时间3分钟。会话窗口是，前后两条消息间隔超过3分钟，那么窗口关闭。
但是如果在规定时间内来的数据，后序再没有数据了，窗口能关闭吗？
			


```



## 场景问题

#### 实时统计整数小时去重用户总数

```mysql
#方案1
按日期小时keyby,然后用一个map记录哪些用户消费过,然后每来一条数据,更新map,更新累加值,累加值更新到hbase。
这个方案状态好管理,这个ttl设置1小时，一小时不会再来数据,map就清理了
缺点：按小时keyby只有一个并行度

#方案2
按userid去keyby，内部存map，key是小时,如果map不含当前小时,执行out.collect。如果包含表明当前小时已经消费过。
获取的流进行

```

#### 5秒输出近一小时top10热门

```mysql
#方案1
滑动窗口一小时,5秒。按spuid进行keyby统计售卖数量。
现在想把所有的keyby商品汇聚到一起,并且能区分不同窗口的。窗口输出时，带上窗口的结束时间end,按end进行key
这样能区分不同窗口，并且同窗口的都收集到一起

#方案2  
keyby，只用一个并行度然后windowAll,也是滑动窗口一小时,5秒。内部用一个map去存spuid和累积数量,
触发时对迭代器遍历找最高的10商品 
缺点：并行度太低了

#方案3定时器



```



#### 双流join不keyby

```mysql
#方案1待改进
按关联key，进行hash然后取模并行度。然后connect,每个分区用一个map去存订单/订单明细进行
缺点：map中数据永远累加，因为永远再进数据，也没法设置ttl

```



#### 双流join？？待处理

```mysql
#2个事实表关联？？？
方案1：
2个流connect之后,执行keyby，在process里用状态存是否来临，每个订单号都有2个map，然后设置ttl，保证历史数据的清理。

#如何进行windowjoin呢？？？



#2个流关联多场景
场景一：2个流同key都只有1条数据
场景二：2个流，其中一个流同key有多条数据,并且时间相差可能很久


#用户去重后,每10s统计近1小时内用户总数


#用户去重后,实时统计每整数小时用户总数

```

#### 小维表广播变量减少shuffle

```mysql
#配置表用广播变量优点
1问题  多并行度下,数据都能关联到
2问题  减少shuffle
3问题  动态控制
如果想实现每个流，多并行度下都能关联到配置表，不会漏。那么维度表按table名keyby，然后connect也能实现，不会丢数据。
但是从kafka消费的数据，都会经过一次keyby的shuffle。不划算，广播变量就能减少数据移动。
```

#### 开窗用处

```mysql
#开窗统计
如果来一条数据，执行一次数据统计更新,写入数据库。实时性最好，不过负载最大。
开窗口5s时总计一次，这个实时性差，但是访问数据库少了,并且写入的是5s统计数据，io也减少了
```



#### 反爬用滑动记数窗口

```mysql
滑动记数,每1条数据，开一个30长度的窗口,当30次后关闭窗口，查看首尾数据时间，是否符合范围。
```



#### 如何不用幂等性保证精准一次

```mysql
比如checkpoint 5分钟保存一次,触发时把这5分钟的订单号等存在一个状态,然后重启时，对于重复消费的kafka数据,校验订单号,决定是否继续写入下游。
flink的filesink写入hdfs实现了预提交和两阶段提交，能保证大部分情况下事务，但是也有极端情况下会有问题。
```



## 性能问题

#### 流重复使用

```mysql
maxwell流，一个流多个表
将多个表分流出来的方式:
	1 kDS多次过滤
	2 kDS一个过滤，多个测输出流
```



#### 算子解析

```mysql
#connect
2个keyedby流进行connect别想太复杂,2个流还是单独处理,只不过2个流之间可以互相使用对方的状态。
2个keyby流connect后，再执行keyby，也是独自各自进行keyby
```



## 代码demo

#### 状态

#### ttl

#### checkpoint

#### 流开窗使用场景

```mysql
#时间滑动
场景，每5分钟统计一次最近的一次最大金额，更新频率就是窗口大小

#时间滚动
每各5分钟统计一次，最近1小时总人数.滑动窗口1小时，滑动步长5分钟


#统计每整数小时订单数,每5秒更新一次，怎么做？？？

计数滚动
计数滑动
会话窗口




#keyedby流窗场景


#情景1单流
下单数据,当3分钟内,订单状态未改为已支付,则订单失效,进行处理

```



#### 流关联





# 源码篇

#### 源码问题

```
再intervaljoined流中，源码对keyed1.connect(keyed2)再进行了keybyc=操作，是干什么的
```



#### 源码解析

```mysql
#clean(F)
经常会对用户的传的map,process等实现接口进行clean操作，
1 主要是检查这些接口实现中,有没有用户自定义的不可序列化的对象。
2 检查闭包清理器是否启用(待了解）,就是你实现的接口有没有引用外部对象,比如实现了一个map接口,接口内部方法，调用了env代码下的一个变量。如果用到外部变量，分布式条件下会出现下面问题:1 对象被拷贝多份，浪费性能。并行度间状态不一致
              
              
              
```

