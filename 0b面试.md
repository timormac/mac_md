# 简历

1-3年和3-5年简历写的内容不一样

面试aaa



# 公司业务数据

### 彩贝壳类型

```
美团是一个综合性的生活服务电子商务平台，主要提供包括餐饮外卖、酒店旅游预订、电影票务、到家服务、共享单车等在内的本地生活服务。美团的业务模式是典型的C2B2C（Consumer to Business to Consumer），P2P通常指的是个人与个人之间的直接交易，没有商家的介入。
彩贝壳自己采购了许多产品，所以应该算是B2C


商务团队（或商家服务团队）：负责与商家建立合作关系，帮助商家在平台上成长，提供营销和广告服务等。这个团队有时也被称为销售团队或BD（Business Development）团队。
```



### 公司100w日活数据

```sql
电商平台的用户活跃度、新增用户数、每日订单数以及下单率这些指标受到多种因素的影响，比如平台的市场定位、用户群体、产品种类、季节性因素、促销活动等。不过，我可以提供一些行业平均水平的参考数据，但请注意这些数据仅供参考，实际情况可能会有所不同。

1. 每日新增用户数：对于一个日活跃用户数(DAU)为100万的成熟电商平台，如果是在正常运营阶段而非大型促销期间，每日的新增用户可能会占日活跃用户的一小部分。一个粗略的估计可能在0.5%到2%之间，这意味着每天的新增用户数可能在5000到20000之间。

2. 每日订单数：每日订单数与平台的转化率密切相关。转化率是指访问电商平台的用户中有多少比例会下单。对于一些成熟的电商平台，转化率可能在1%到5%之间。以2%的中等转化率计算，如果日活跃用户数为100万，那么每日的订单数可能在2万到5万之间。

3. 下单人数占活跃人数的比率：这个比率实际上就是上面提到的转化率。一个电商平台被认为是表现良好，如果其转化率能够达到3%以上。不过，这个数字对于不同的电商平台和市场来说差异很大。例如，一些高度专业化或者提供高价值商品的平台可能会有更低的转化率，而一些面向快速消费品市场的平台可能会有更高的转化率。

请记住，这些数字只是基于行业平均水平的大致估计，并不代表任何特定电商平台的实际情况。您应该根据自己公司的具体情况进行分析和比较。
```



### 10w 日活

每日3000单，转化率3%  新增用户数是活跃的0.5% :300-500人

客单价是150元,利润10%  一个月135w 。

```
在中国，一个拥有10万日活跃用户（DAU）的电商平台可以认为是一个中等规模的平台。中国的电商市场非常庞大，由几个巨头如阿里巴巴的天猫和淘宝、京东、拼多多等主导，它们的日活跃用户数以亿计。但是，10万日活跃用户对于一个专注于特定细分市场或者新兴的电商平台来说是一个不错的成绩，可能意味着这个平台在它的细分市场中具有一定的影响力和用户基础。

至于具体的运营数据，这些数字会根据平台的业务模式、用户群体、市场定位等因素而有很大的差异。以下是一些非常粗略的估计，仅供参考：

1. **每日新增用户数**：这个指标受多种因素影响，包括市场扩张速度、品牌知名度、营销活动等。对于一个成熟的平台，每日新增用户数可能在千到数千不等。新兴平台可能会有更高的比例，特别是在推广期。

2. **每日下单量**：这取决于用户的购买频率和平台的商品种类。一般来说，电商平台的转化率（即浏览到购买的转化）可能在1%到10%之间。假设转化率为3%，那么10万日活跃用户可能会产生大约3000单的日订单量。

3. **用户流失率**：这是衡量用户停止使用服务的速度。对于电商平台，年流失率可能在10%到50%之间，具体取决于用户黏性和市场竞争。如果按月计算，流失率可能在1%到4%之间。但这些数字可能因平台而异，并且在不同的成长阶段也会有所不同。

4. **商家的利润比**：商家的净利润率取决于他们的成本结构和定价策略。在电商平台上，商家的利润通常是GMV（商品交易总额）的一部分。利润率可能在5%到20%之间，但这会因行业、产品类型、品牌定位等不同而有很大差异。

需要注意的是，这些数字仅供参考，实际情况会根据具体的平台和市场条件有很大的不同。要获得精确的数据，通常需要访问公司的内部运营数据或者行业报告。
```



### 运营数据

统计新增用户来源，微信赠送功能注册的新用户，未知来源注册的新用户数。

如果微信赠送功能，增加新用户，那么就会给大额红包，红包使用率等问题。

### DAu和WAU

```
日活跃用户（DAU）、周活跃用户（WAU）、月活跃用户（MAU）和年活跃用户（YAU）是衡量电商平台用户活跃度的常用指标。这些指标通常用于分析用户参与度、平台粘性和用户忠诚度。

要从日活跃用户（DAU）估算周活跃用户（WAU）、月活跃用户（MAU）和年活跃用户（YAU），我们需要假设或有实际数据关于用户的访问频率。不同的平台和应用场景会有不同的用户行为模式。例如，有的用户可能每天都会访问，而有的用户可能只在周末访问。没有具体的数据，我们只能做一些假设。

WAU/DAU = 1：意味着每天的活跃用户在整个周内都是同一批用户，没有新用户加入，用户粘性极高。
WAU/DAU = 2-3：意味着有一定比例的用户在一周内多次访问，表明有不错的用户粘性和参与度。
WAU/DAU > 3：意味着用户回访率很高，平台在一周内吸引了大量的重复访问，这表明平台运营状况良好，用户粘性很强。
```





# 项目遇到问题

### kafka消息积压项目宕机

```sql
批量更新订单数据，maxwell是监控所有表,导致Kafka多了几百万数据。注意增加字段，不会有upsert的kafka信息
造成影响：
	/* 	监控工具直接短信报警
	   	数据积压了，后续进kafka其他表消息，无法消费到
	   	flink实时任务挂掉了，后台实时面板不更新
	*/
	
	解决方法:
					因为分区3个，只能3个消费者,开多线程。（不知道flink任务能开启多线程吗）
				  线程数是通过zookeeper动态调整的，我把核心线程数调成了8个，核心线程数改成了10个
				  
	复盘:		
					订单系统的批量操作一定提前通知下游系统团队。
					下游系统团队多线程调用订单查询接口一定要做压测。
					对消息积压情况加监控
	
```

### 算法要数据dwt层

算法要用户画像，

用户所有数据，

在线商品说有数据，

商户所有数据

每次看执行任务，最难的就是这个job，

弄了个dwt层，然后出问题，有一次导表，数据异常，有重复数据，然后dwt累加整层就废了。后面dwt分层拆开了，弄个dws日汇总。

注意dws命名的时候，要按功能分域，便于其他同事理解这块sql用途，算法域。

去百度下目前互联网数据仓库分层



### OOM 的解决方法

1  看sql的执行计划，看看有没有优化的地方

   熟悉数据情况，人工给数据分组，再解组

2 手动指定mr数量，增加并行度

3 设置参数jvm虚拟机的Xxm最大堆内存

# 技术栈

1 准备哪些技术栈

​	 永远学不完，准备真实自己项目用到的框架

2  每个技术栈应该怎么写

​	项目用到的核心技术栈，要拆分具体模块，写到的就会问，不会的不要写，问到了不会答就很尴尬

​    非核心技术栈写了解就行，不要拆分模块，仅限于使用，取数等，比如redis

   例子:spark的多模块，比如spark-core,spark-sql,spark-structStreaming没学不要写，然后任务执行流程，rdd原地，shuffle机			   			制,spark调优等。



对于具体的技术栈，可以仔细写一下划分模块,比如hbase读写流程，运行架构，rowkey设计,二级索引，phoneix等

技术栈原则:   写到的都要会，对于一些不常用不熟悉的，直接就写个了解azkaban等，不要展开，只限于写脚本，别的没深入



# 项目(github上找)

### 实时推荐项目

不要直接写实时数仓的建设

flink项目用github上的实时推荐系统，对接算法提供数据

### 离线数仓更新项目(离线在线混搭)

对于原来的sql也做了优化，之前任务，更新1条就要重写整个订单表的分区业务数据。

需解决问题:			

​			程序挂了，数据怎么保持一致。脚本校对数量，短信通知。

​			因为实时任务一直再跑而且记录到消费到哪的数据了，人工介入比较难

​			或者更改flink代码，更改过滤掉某时间点之内的数据。flink第一次也要这样。



ods层可以实时做，最简单的。

dwd层如何实时做呢？？？？会遇到哪些场景呢？

因为表关联之后，会有变化数据，所以怎么才能实时做。多次join，同一条数据，1-24小时的表，每次都汇总前面表，然后取最大分区的。这样就能做了，随着dwd改了，dws也要更新的。



当凌晨查询flink同步的表时，会锁表吗？如果这时候flink数据插入，导致数据进不去怎么办的？

对于分区表还好，因为flink凌晨写入的是第二天的分区了。非分区表，只有一张的表，就锁表了

```sql
Hive 本身是建立在 Hadoop 的 HDFS 之上的，并不是一个真正意义上的事务型数据库，它的设计初衷是用来做批处理的，所以它的表锁定机制并不像传统关系型数据库那样严格。

对于 Hive 来说，它的 "锁" 更多的是在 Hadoop 的文件系统层面上。Hive 1.2.0 版本之后引入了一些轻量级的事务处理和行级别的锁定，但这些通常用于支持 ACID（原子性、一致性、隔离性、持久性）操作，需要开启 Hive 的事务功能，并且使用支持事务的表格式（如 ORC 格式）。如果你的 Hive 表没有启用事务特性，那么它基本上不会有类似关系型数据库中的锁表行为。

然而，当 Hive 正在读取数据时，如果 Flink 任务尝试写入相同的数据文件，可能会遇到并发问题。这是因为 HDFS 是一个写一次读多次的文件系统，不支持对文件的并发写操作。如果 Flink 任务在写入时文件被 Hive 任务读取，可能会导致写操作失败。

为了处理 Hive 和 Flink 之间的并发问题，你可以考虑以下几种策略：

时间窗口隔离：安排 Flink 实时写入作业和 Hive 批量读取作业在不同的时间窗口执行，以避免并发冲突。

基于分区的写入：如果使用的是分区表，Flink 可以写入一个新的分区，而不是正在被 Hive 查询的分区。这样，Hive 查询时不会读取 Flink 正在写入的分区。

使用临时表：Flink 写入数据到一个临时表，然后在 Hive 的低峰时段将这些数据批量转移到主表中。

流式处理与批处理分离：考虑将流处理和批处理的数据分开存储，流处理写入实时表，批处理从历史数据表读取，通过定期的作业将实时表的数据合并到历史数据表中。

使用 ACID 表：如果你的 Hive 版本支持，并且你的用例可以容忍相关的性能开销，可以考虑使用 Hive 的事务表功能。这将允许 Hive 和 Flink 使用行级锁，从而更好地支持并发操作。

数据湖解决方案：考虑使用更先进的数据湖解决方案，如 Delta Lake 或 Apache Hudi，这些解决方案提供了更好的并发控制和事务管理。

在实施上述任何策略之前，重要的是要了解你的数据访问模式，并对 Hive 和 Flink 的交互进行充分的测试，以确保你的数据管道的稳定性和可靠性。
```



dws基于dwd层，dwd不跑完没发弄。



2套体系同时再跑，然后对数，稳定知道，老系统停下来。对于有时特别小的误差，不要了，问题不好找，用于分析。









# 集群规模

群里有个人 28台,192G,32C，80T

阿里云上cpu只有1,2,4,8,16,32,64核的

选的是16cp 128g内存  40T硬盘   5台  一个服务器一台1年是3w 5台15w。



总订单数2000w条,5年，日活待定，日订单待定，新增用户数待定



# flume 

b站视频,flume问的挺多的

https://www.bilibili.com/video/BV1Va4y1X7Am/?spm_id_from=333.999.0.0&vd_source=dc2f0659a9d317ea4b839219ee320ab7

# 数仓



### 脏数据

来源  

1 业务数据或者埋点数据内容中有\t，sqoop导入时没做处理，后端没做非法字符校验

2  老的历史数据模型不一致问题

3 特殊场景下触发的bug，后端没测出来，缺少关键字段数据

4 order表中有的商品id字段应该创建了应该落，不过有的代码没落，他们补充主 订单表拿，但是用的时候用到这个字段

###  模型改善(dwt删除)

后续给删除了，总计用户所有销量，1年内销量等。有错误数据，每次都要洗。

或者把数据按天分区，只洗某一天的。

某一天数据同步出问题了。后续跑批，导致dwt出问题，只能回滚后续几天。		 

### 指标体系

业务数据

商品主题：

​	每日各品牌商家订单数，销售额，购买人数，退单金额，退单数量

​	每日各品类的订单数，销售额，购买人数，退单金额，退单数量

​	每日爆款商品top10，订单数，销售额，购买人数，退单金额，退单数量



交易主题：

​	每日订单数，订单金额，订单人数，退单数，退单人数，退单金额

​	每日各渠道带来的订单金额，订单数量，订单人数(微信公众号，小程序推广，直播，app购买)



用户主题：

​	每日新增用户数，

​	

用户行为数据

用户主题：

​	每日活跃用户数，活跃用户数，回流用户数

​	漏斗分析，每日首页浏览用户数，商品详情页用户数，当人下单人数，支付人数



app设计:

​	各个导航图标的点击数量







数仓分层



dwd层

数据清洗：数据格式不对的统一数据格式：比如日期格式。默认字段空和null转成一致，因为历史表可能不统一

数据加密：手机号等

增加常用字段主键：增加商户id，维护id，签约人员id，避免需要关联时关联多个表来拿指定字段。