# 项目详细

#### 实时推荐项目



#### 数据仓库离在线混搭

```sql
#哪些层哪些表能用flink代替
ods可以，dwd待定，待思考。

用分区方法遇到的问题，有的表没有分区，改成分区表，则相关依赖的sql都用改。
所以对于没分区的表，继续用原来的表，这种表通常不台大。

#凌晨读取数据，锁表问题
肯能导致数据写入不进去，需要去试。
解决方法：
1 分区，这里有个问题，要更改原hive任务的hql
2 hive的ACID表

用分区方法遇到的问题，有的表没有分区，改成分区表，则相关依赖的sql都用改。
所以对于没分区的表，继续用原来的

#要想实现dwd层，数据更新问题
hive新版本的ACID表，现在读取性能更好，用ACID表来做

#kafka数据的精准一次性消费问题
用flink写入kafka一次性消费，详情看flink.md。代码实现复杂，并且影响吞吐量。
最简洁的方法是用table_api来写,然后出现问题了，手动去分区重跑数据。
tableAPI好像也能实现精准一次消费。


#任务故障，怎么数据恢复
正常情况重启就行，kafka数据继续消费。
如果真的出现数据条数不同，数据多了或者丢了，用原来的离线脚本执行问题分区。

#dwd改写，开发难度大，耗时高
本来hive就是为了加快速度的，减少mr编写。
如果实现了dwd改写，那也很复杂，想象怎么能提高dwd改写速度。
目前的思路是每小时执行一次，然后12点合并，但是怕有的表会改动数据，或者关联不到的情况。待处理

#什么时候接入系统的
把以前离线仓库的脚本任务的主任务，涉及到的表用flink任务重新编写，每天对比数据，数据稳定之后，替换表数据来源。

#怎么分配内存使用的
压侧，顶峰等具体看flink优化视频里有

```



# 其他



1.彩贝壳公司，干过的项目。

前半年是数据需求拉取



维护日常数据需求拉取 到至今



构建新的数据仓库模型，任务迁移 到至今

最大的问题是，任务太多了，有一些任务指标已经不知道有没有人去看了，

对于这种累计型任务，建议设置一个最近多少个月没人观看，然后终止任务，节省集群功能。

因为报表系统问题，待完成。



集群数据质量监控问题监控

有时候总是出现数据数据少，原因很多，后端落的不合理，新模型逻辑变动覆盖不到。

变动沟通不及时，没人漏斗查看数据减少，超出规模，将异常数据找出，超出规模报警。



对接算法，实时推荐系统。



# 框架详细

#### kafka

```sql
#怎么合理设置topic分区数

#消息积压怎么处理

#精准一次性消费

#乱序问题怎么处理
```

#### hadoop

```sql
#简历内容hadoop详细到点,
```

