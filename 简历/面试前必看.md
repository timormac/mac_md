# 项目详细

## 实时推荐项目

改架构模型:  前端埋点，原本是批发送，或者用户下线时批量发送，点一下发一下。后端下订单直接发送到kafka消息队列。沟通







## 数据仓库离在线混搭

离在线混搭和实时数据仓库区别：

​	个人理解，离线在线混搭，解决的问题，是大量任务在凌晨执行，对于数据查询的实时性没那么高，只是为了提高白天资源利用率，

​    用不到毫秒级别的响应。离在线混搭是为了减少一些当天数据的处理时间，对于历史数据和涉及到历史统计的，还是要用离线仓库去  	做，不可能用实时任务去完全替代。并且一些很复杂的hql，clickhouse没发处理，比如流失率等等，7天内连续登陆问题，复购率

 

​	而实时仓库，是为了毫秒级别的响应，查看app，当天运营状态，所以要引入clickhouse框架等。

​	

#### 需要解决问题

flink写hive要解决小文件问题。



#### 方案1：

flink直接写入hive表上，这个夭折了，开发难度大，自己维护幂等性难，故障恢复处理难，hive中acid事务表无法处理。

#### 方案2:

 flink写入hbase表，通过hive对接hbase表。但是hive表联通hbase表后，就无法使用 分区功能了，所以为了能够快速定位当日数据，要为hbase添加dt字段索引，并且这样也不会改变下一层的用到这张表的任务。

用hbase还有些优化的地方，比如hive使用hbase表的原理。hive用hbase表的话，执行mr任务，还能多平行度吗？如何多并行度多，还能手动指定map数吗等等。



**方案2实现**

```
有什么可以帮你的吗

我在hive上如何对接hbase中的表，当我在hbase上更新数据时,hive表会增加数据吗？当我在hive表导入数据时，hbase会自动创建插入数据的索引吗？

Apache Hive 是一个数据仓库系统，用于查询和管理大型数据集，而 Apache HBase 是一个分布式、可扩展的大数据存储。Hive 可以通过自定义存储处理器（Storage Handler）来与 HBase 集成，使得你可以通过 Hive 来查询 HBase 中的数据。

要在 Hive 上对接 HBase 中的表，你需要使用 Hive 提供的 HBaseStorageHandler。以下是一个简单的例子，展示了如何在 Hive 中创建一个映射到 HBase 表的外部表：

CREATE EXTERNAL TABLE hive_table_name(key int, value string)
STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
WITH SERDEPROPERTIES ("hbase.columns.mapping" = ":key,cf:value")
TBLPROPERTIES ("hbase.table.name" = "hbase_table_name");
在这个例子中，hive_table_name 是 Hive 表的名称，hbase_table_name 是 HBase 表的名称，cf 是 HBase 中的列族。

对于你的问题：

当你在 HBase 上更新数据时，Hive 表是否会增加数据？

如果你在 HBase 中插入新的行或更新现有行，这些更改会即时反映在 Hive 的查询结果中，因为 Hive 表只是 HBase 数据的一个视图。但请注意，Hive 不是为实时查询优化的，可能会有一些延迟。

当你在 Hive 表导入数据时，HBase 是否会自动创建插入数据的索引？

当你往 Hive 表中插入数据时，这些数据实际上是被写入到 HBase 表中的。因为 Hive 表是通过 HBaseStorageHandler 映射到 HBase 表的，所以插入操作会转化为 HBase 的 Put 操作。然而，HBase 默认不会为数据创建索引；它只是根据 Row Key 存储和检索数据。如果你需要在 HBase 中创建二级索引，你需要使用额外的工具或自己实现逻辑来维护索引。

请记住，要使得 Hive 与 HBase 集成，你需要在 Hive 的 classpath 中包含 HBase 和 ZooKeeper 的配置文件，并且确保 Hive 能够访问运行 HBase 的 Hadoop 集群。此外，Hive 与 HBase 的集成通常用于批量处理，而不是实时查询，所以在设计系统时应考虑数据延迟和读写吞吐量。

那如果我在hbase上对一个rowkey为1数据，更新3次，那么hive查询的数据是只有1条rowkey为1的数据，还是4条rowkey为1的数据

当你在 HBase 中对同一个 rowkey 更新数据时，HBase 会根据其版本管理特性来处理这些更新。HBase 中的每个 cell（由 rowkey、列族、列限定符确定）可以存储多个版本的数据，版本通过时间戳进行区分。

默认情况下，当你对同一个 rowkey 进行更新操作时，HBase 会保留每次更新的版本，除非你在创建表的时候指定了版本的数量（VERSIONS）。如果没有指定版本数量，HBase 默认通常保留一个版本。这意味着新的更新会覆盖旧的数据。

在 Hive 中查询 HBase 表时，Hive 通常只会看到每个 cell 的最新版本的数据。因此，如果你对 HBase 中某个 rowkey 的数据更新了3次，Hive 查询结果中只会有一条 rowkey 为1的数据，并且该数据将是最新版本的数据。

如果你需要在 Hive 中查询 HBase 的旧版本数据，你需要在创建 Hive 表时指定版本信息。但是，这通常不是 Hive 使用的典型用例，因为 Hive 主要用于处理最新的数据快照，而不是用于查看数据的历史版本。如果你需要处理多个版本的数据，可能需要在 HBase 中直接操作或使用其他支持版本控制的系统。
```





**方案1**

```sql
#哪些层哪些表能用flink代替
ods可以，dwd待定，待思考。

用分区方法遇到的问题，有的表没有分区，改成分区表，则相关依赖的sql都用改。
所以对于没分区的表，继续用原来的表，这种表通常不台大。

flink没法读写acid表，自己要维护事务插入，也没法对接hive的acid因为不知道实现原理。
代码开发难度太大，注意问题太多，重复数据处理，故障数据恢复等。
只对几个主表进行这么操作，主业务表，其他支线都根据主表来跑，其他的是能并行的。


#凌晨读取数据，锁表问题
肯能导致数据写入不进去，需要去试。
解决方法：
1 分区，这里有个问题，要更改原hive任务的hql
2 hive的ACID表

用分区方法遇到的问题，有的表没有分区，改成分区表，则相关依赖的sql都用改。
所以对于没分区的表，继续用原来的

#要想实现dwd层，数据更新问题
hive新版本的ACID表，现在读取性能更好，用ACID表来做。
flink不支持读取和写入acid表

#kafka数据的精准一次性消费问题
用flink写入kafka一次性消费，详情看flink.md。代码实现复杂，并且影响吞吐量。
最简洁的方法是用table_api来写,然后出现问题了，手动去分区重跑数据。
tableAPI好像也能实现精准一次消费。


#任务故障，怎么数据恢复
正常情况重启就行，kafka数据继续消费。
如果真的出现数据条数不同，数据多了或者丢了，用原来的离线脚本执行问题分区。

#dwd改写，开发难度大，耗时高
本来hive就是为了加快速度的，减少mr编写。
如果实现了dwd改写，那也很复杂，想象怎么能提高dwd改写速度。
目前的思路是每小时执行一次，然后12点合并，但是怕有的表会改动数据，或者关联不到的情况。待处理

#什么时候接入系统的
把以前离线仓库的脚本任务的主任务，涉及到的表用flink任务重新编写，每天对比数据，数据稳定之后，替换表数据来源。

#怎么分配内存使用的
压侧，顶峰等具体看flink优化视频里有

```



# 其他



1.彩贝壳公司，干过的项目。

前半年是数据需求拉取



维护日常数据需求拉取 到至今



构建新的数据仓库模型，任务迁移 到至今

最大的问题是，任务太多了，有一些任务指标已经不知道有没有人去看了，

对于这种累计型任务，建议设置一个最近多少个月没人观看，然后终止任务，节省集群功能。

因为报表系统问题，待完成。



集群数据质量监控问题监控

有时候总是出现数据数据少，原因很多，后端落的不合理，新模型逻辑变动覆盖不到。

变动沟通不及时，没人漏斗查看数据减少，超出规模，将异常数据找出，超出规模报警。



对接算法，实时推荐系统。



# 框架详细

#### kafka

```sql
#怎么合理设置topic分区数

#消息积压怎么处理

#精准一次性消费

#乱序问题怎么处理
```

#### hadoop

```sql
#简历内容hadoop详细到点,
```

