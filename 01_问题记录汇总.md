# 杂问题

### sqoop报错无-e command

1  sqoop脚本，掉sqoop指令时加入#注释，在shell里看着没问题，但实际会将#注释传递给sqoop指令，执行报错





# flink

## 问题记录

#### 可用slut为0但是能提交任务

#### yarn-session模式起不来任务

```sql
#slut为0 
看到flink UI界面，显示slut 为0 ，看到各集群free -h  剩余没有大于1.5G的内存。看了下配置文件,需要task的内存默认是1.7G,所以可以插槽为0 
#application任务被杀
启动任务后显示任务被yarn杀掉
原因： 如果 Flink 或者用户代码分配超过容器大小的非托管的堆外（本地）内存，部署环境可能会杀掉超用内存的容器，造成作业执行失败。
#更改配置文件后连yarn-sesion都起不来
为了资源够slut,更改flink配置文件，发现起不来了。后面查阅发现，好像比如jobmanager和taskmanager有一定内存比例的，而且分给某些线程的内存要在固定60m-256m范围之间，因为只改了jobmanager和taskmanager的内存配置，所以起不来了。
```



yarn-application模式，可用slots是0，但是能提交一个3并行度的任务,不知道为什么

只能提交第一个任务，第二个任务提交时，提交不了了，一直卡在了，显示

Deployment took more than 60 seconds. Please check if the requested resources are available in the YARN cluster
Deployment took more than 120 seconds. Please check if the requested resources are available in the YARN cluster



如果时先启动yarn-session服务器，发现连第一个任务都启动不了，不知道为什么，一直卡在申请container



#### log4j日志不打印

代码里指定了log4j打印目录，在idea能自己创建目录，上传到集群，log日志无法生成



#### flink任务每次临时下载jar包

fink任务每次临时下载jar包，那么如果我执行多个任务，下载多次吗？

还是说第一次下载jar包后，存在本地某个目录，以后先去目录找，再决定是否下载

#### hdfs的项目包无法执行

下面2个都是yarn-application模式，不过本地的jar能正常执行，但是hdfs上的jar无法正常执行，报错如下：

 No ClusterClientFactory found. If you were targeting a Yarn cluster, please make sure to export the HADOOP_CLASSPATH  environment variable or have hadoop in your classpath.

​	个人理解就是如果通过hdfs 必须在hdfs上有jar包并且必须参数指定lib才行，或者说是没有连接上project1:8020就是没找到hdfs所在的执行环境

```shell
./bin/flink run-application -t yarn-application -c com.timor.flink.learning.demo.A3_WordCountStreamSocket  hdfs://project1:8020/flink-jars/git_flink_learning_1.17-1.0-SNAPSHOT.jar


./bin/flink run-application -t yarn-application -c com.timor.flink.learning.demo.A3_WordCountStreamSocket   ./git_flink_learning_1.17-1.0-SNAPSHOT.jar
```



2任务槽设置中，是在flink配置文件设定的，但是flink on yarn，其他子节点都没安装flink，设置插槽数量有什么用？？

#### batch应用场景

什么时候用batch批，什么时候用stream流模式

flink的分区策略有什么用，大部分flink是消费消息队列kafka，而kafka的API应该是有自己的数据发送模式，flink设置了应该没用

#### 三流join怎么实现

  3流以上的join怎么实现的，目前用connect+ process只能实现2流join

 有个问题就是窗口我之前的map流设置并行度为2，keyby返回的流不能设置并行度，但是用keyby获得的窗口默认并行度是8



#### 无继承关系却满足范型

```
 //问题 :forGenerator方法需要传入一个WatermarkGeneratorSupplier，但是老师模仿的实现的是WatermarkGenerator
 //这2个不一样WatermarkGenerator和WatermarkGeneratorSupplier没有父子关系为什么能传进去
// WatermarkStrategy.forGenerator()
```

下面问题也是一样的

```java
WatermarkStrategy<WaterSensor> watermarkStrategy = WatermarkStrategy
    .<WaterSensor>forBoundedOutOfOrderness(Duration.ofSeconds(2))
    .withTimestampAssigner(new SerializableTimestampAssigner<WaterSensor>() {
      @Override
      public long extractTimestamp(WaterSensor element, long recordTimestamp) {
      });
 //WatermarkStrategy.forBoundedOutOfOrderness()方法，点进源码看到的是:
 static <T> WatermarkStrategy<T> forBoundedOutOfOrderness(Duration maxOutOfOrderness) {
        return (ctx) -> new BoundedOutOfOrdernessWatermarks<>(maxOutOfOrderness);
    }
   //源码显示的方法返回值是WatermarkStrategy，不过new BoundedOutOfOrdernessWatermarks<>(maxOutOfOrderness)，点进去并没有实现WatermarkStrategy接口，看不懂了，为什么new BoundedOutOfOrdernessWatermarks能用WatermarkStrategy接
   
   BoundedOutOfOrdernessWatermarks类,实现了WatermarkGenerator接口，并且这个接口是个初始接口，和watermarkStrategy没关系
  class BoundedOutOfOrdernessWatermarks<T> implements WatermarkGenerator<T>
    
      
      
```

#### 传入方法在哪被调用

看一些源码的时候，有时候需要传入一个借口，实现某个方法，比如flink的自定义map方法，有个问题，就是我现在想知道，这个传入的map方法，到底是谁在哪一步开始调用的，现在一直没头绪

#### watermark传递机制

flink中waterMark是怎么传递的，比如先map 然后 process，不同算子之间，是根据流过的数据来更新watermark吗

#### 定时器重复注册

keyBy后的流，同一个key，注册多次定时器，会发生什么因为topn代码中，流的process注册了定时器，并且同一个key重复注册了，

不会出问题吗？

#### ArrayIndexOutOfBoundsException

A2_TopnWindowAll有个bug，就是总是报错.ArrayIndexOutOfBoundsException: -2147483648，不知道原因

已经确定不是nc输出错误数据的问题了。好像设置并行度为2的时候就不会出问题了

#### windowall并行度不为1

在 A2_TopnWindowAll有个问题，就是用了windowall，最后输出结果还是多个并行度结果

#### 不同执行模式区别

去csdn查一下，session和standalone，application模式应用场景与区别



#### checkpoint未整理问题

1  为什么cep设置为hdfs路径时，pom文件要导入hadoop依赖，代码里没有用haddoop的包啊

3  checkpoint不是应该和status状态编程连用吗？为什么demo里可以单独用

2	cep会将数据携带一个barrier，让各个算子记录当前状态，不过没有那么简单

例如 kafka源2个并行度消费，那么每个并行度需要记录消费了几个分区，并且每个分区消费位置,

当某个算子从2并行度更改到4并行度，那么如果只是给一个数据携带barrier那么会出现某个并行度没有barrier，

所以具体怎么样实现的barrier不清楚。以及当从4并行度聚合到2个并行度，那么barrier又是怎么实现的也不清楚。

当2并行度聚合到1个并行度，当上游的2个barrier数据到达时间有延迟，比如一个分支到了3个数据，另外一个分支的barrier才到

那么合并后的barrier什么时候保存状态

#### flink-session起不来

更改配置文件后连yarn-sesion都起不来
为了资源够slut,更改flink配置文件，发现起不来了。后面查阅发现，好像比如jobmanager和taskmanager有一定内存比例的，而且分给某些线程的内存要在固定60m-256m范围之间，因为只改了jobmanager和taskmanager的内存配置，所以起不来了。

要怎么配置内存占比呢，才能让集群跑起来



## 问题已解决

#### 水位线不推进

1  事件水位线推进，自己的代码有bug：

```java
/*bug原因找到了,因为没设置并行度导致默认是8个线程，而水位线必须8个流里的数据都有数据并且事件时间更新到10s时才触发process执行
*因为之前输入的key都是a,b导致其他线程没数据，导致其他线程水位线时间不更新，所以尽管a,1000但是还是不触发process窗口关闭
* 后面设置并行度为2,就好了，不过必须a,b 2个事件时间都超过10
          * 为了避免这种情况可以设置空闲时间等待.withIdleness(Duration.ofSeconds(10))
          * //空闲等待10s，即当10s内其他分区没有数据更新事件时间是，等10s，按最大的时间时间同步到其他没数据的分区
* */
```

#### 定时器重复注册

在KeyedProcessFunction中可以住车定时器。processElement函数中每次处理一条数据，这样重复注册定时器，不会导致定时任务重复调用吗？

答案是不会，应为Flink内部使用的HeapPriorityQueueSet来存储定时器，一个注册请求到来时，其add()方法会检查是否已经存在，如果存在则不会加入。并且是根据key来注册的。如果重复注册并且更改触发时间的话，需要自己去测一下

#### 找不到flink-kafka类

flink本身并不包含这些拓展文件，虽然我们代码里有kafkasource，但是是pom自己导入的，不是flink自带的，所以需要我们自己打包带的jar包，或者上传服务器

pom里配置了这个

<!--  连接kafka流 -->
<dependency>
    <groupId>org.apache.flink</groupId>
    <artifactId>flink-connector-kafka</artifactId>
    <version>${flink.version}</version>
    <scope>provided</scope>
</dependency>









#### yarn-session模式起不来任务

```sql
#slut为0 
看到flink UI界面，显示slut 为0 ，看到各集群free -h  剩余没有大于1.5G的内存。看了下配置文件,需要task的内存默认是1.7G,所以可以插槽为0 
#application任务被杀
启动任务后显示任务被yarn杀掉
原因： 如果 Flink 或者用户代码分配超过容器大小的非托管的堆外（本地）内存，部署环境可能会杀掉超用内存的容器，造成作业执行失败。
#更改配置文件后连yarn-sesion都起不来
为了资源够slut,更改flink配置文件，发现起不来了。后面查阅发现，好像比如jobmanager和taskmanager有一定内存比例的，而且分给某些线程的内存要在固定60m-256m范围之间，因为只改了jobmanager和taskmanager的内存配置，所以起不来了。
```



#### TableApi用moudule时找不到类

把hadoop-mapreduce-..jar拷贝到flink中，其他的方法都不解决根本。这个最好使，在word里

坑已经被视频趟过了



#### kafka.consumer.OffsetResetStrategy

```mysql
#报错
cannot assign instance of org.apache.kafka.clients.consumer.OffsetResetStrategy to field org.apache.flink.connector.kafka.source.enumerator.initializer.ReaderHandledOffsetsInitializer.offsetResetStrategy of type org.apache.kafka.clients.consumer.OffsetResetStrategy in instance of org.apache.flink.connector.kafka.source.enumerator.initializer.ReaderHandledOffsetsInitializer

#原因
根本原因是Flink从Java和UserCode Classpath动态加载依赖项。有些类可以由不同的类加载器加载，然后将它们的类型分配给彼此。

#解决方法：
flink的conf.yaml文件加一条
echo 'classloader.resolve-order: parent-first' >> flink/conf/flink-conf.yaml

#问题解决来源
https://stackoverflow.com/questions/72266646/flink-application-classcastexception

```



#### flink参数设置单容器核数不生效

因为容量调度里里是按内存分核的，所以要改yarn的配置。是yarn的问题



#### flink连接hive时报错找不到方法

NoSuchMethodError: com.google.common.base.Preconditions.checkArgument

基本已经定位到了就是hadoop-common再个包导致的，视频没导入，gpt推荐的，很坑

具体链接：https://blog.51cto.com/u_15278282/4221694

在hadoop目录下的/export/server/hadoop/share/hadoop/common/lib文件夹中，存在着guava-27.0-jre.jar这个包，而在/export/server/hive/lib文件夹中，存在着guava-19.0.jar和guava-27.0-jre.jar这两个对应的包，此时发生了包冲突，产生了错误，因此这里需要把guava-19.0.jar的包删除













# hive

### hive API找不到驱动

Exception in thread "main" java.sql.SQLException: No suitable driver found for "jdbc:hive2://project1:10000/default"

bug手写url,user信息去创建hive连接没问题，读取property报错。

原因是property文件中url="project1",这里不应该加''"",读取的数据带引号

